{"meta":{"title":"knight","subtitle":null,"description":null,"author":"zhugy","url":"http://zhugy.com"},"pages":[],"posts":[{"title":"Tensorflow常用命令","slug":"tensorflow","date":"2017-09-06T04:38:00.871Z","updated":"2017-09-06T04:37:45.000Z","comments":true,"path":"2017/09/06/tensorflow/","link":"","permalink":"http://zhugy.com/2017/09/06/tensorflow/","excerpt":"1. the difference sparse_softmax_cross_entropy_with_logits: labels must have the shape [batch_size] and the dtype int32 or int64. Each label is an int in range [0, num_classes-1] softmax_cross_entropy_with_logits: labels must have the shape [batch_size, num_classes] and dtype float32 or float64. Labels used in softmax_cross_entropy_with_logits are the one hot version of labels used in sparse_softmax_cross_entropy_with_logits.","text":"1. the difference sparse_softmax_cross_entropy_with_logits: labels must have the shape [batch_size] and the dtype int32 or int64. Each label is an int in range [0, num_classes-1] softmax_cross_entropy_with_logits: labels must have the shape [batch_size, num_classes] and dtype float32 or float64. Labels used in softmax_cross_entropy_with_logits are the one hot version of labels used in sparse_softmax_cross_entropy_with_logits. 2. 配置tensorlfowconfig = tf.ConfigProto() # 配置gpu资源随着需求增加，不设置会占用所有gpu资源 config.gpu_options.allow_growth = True with tf.Session(config=config) as sess: sess.run(init) # Creates a graph. with tf.device(&apos;/gpu:2&apos;): a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&apos;a&apos;) b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&apos;b&apos;) c = tf.matmul(a, b) # Creates a session with allow_soft_placement and log_device_placement set # to True. sess = tf.Session(config=tf.ConfigProto( allow_soft_placement=True, log_device_placement=True)) # Runs the op. print(sess.run(c)) allow_soft_placement:If you would like TensorFlow to automatically choose an existing and supported device to run the operations in case the specified one doesn’t exist, you can set allow_soft_placement to True in the configuration option when creating the session. log_device_placement:To find out which devices your operations and tensors are assigned to, create the session with log_device_placement configuration option set to True 3. 配置超参数flags = tf.app.flags FLAGS = flags.FLAGS flags.DEFINE_float(&apos;learning_rate&apos;,1e-3,&apos;Initial learning rate&apos;) flags.DEFINE_integer(&apos;max_step&apos;,20000,&apos;Number of steps to run trainer&apos;) flags.DEFINE_integer(&apos;hidden1&apos;,128,&apos;Number of units in hidden layer1&apos;) flags.DEFINE_integer(&apos;hidden2&apos;,32,&apos;Number of units in hidden layer2&apos;) flags.DEFINE_integer(&apos;batch_size&apos;,100,&apos;Batch Size&apos;) # 引用的时候直接调用： FLAGS.max_step 4. cnn初始化weights = tf.Variable( tf.truncated_normal([IMAGE_PIXELS, hidden1_units], stddev=1.0 / math.sqrt(float(IMAGE_PIXELS))), name=&apos;weights&apos;) biases = tf.Variable(tf.zeros([hidden1_units]), name=&apos;biases&apos;) tf.truncated_normal:正态分布，超过均值两个标准差的值会重新选择（截断）,stddev参数是标准差，一般设置为1/sqrt(n)，其中n为输入层的size b一般初始化为0 5. 保存中间结果 Checkpoint &amp; 并重新加载saver = tf.train.Saver() ... # saver只会保存最新的5次保存结果 saver.save(sess, FLAGS.train_dir, global_step=step) # reload in the future model = tf.train.get_checkpoint_state(FLAGS.model_dir) if model and model.model_checkpoint_path: print(model.model_checkpoint_path) saver.restore(sess, model.model_checkpoint_path) 6. 打开log日志 tensorflow日志分5个依次严重的等级：debug,info,warn,error,fatal。tf默认是warn，可以通过下面的语句修改log等级。设置INFO后，tf.contrib.learn训练loss将会每隔100次打印结果。 tf.logging.set_verbosity(tf.logging.INFO) 7. 日志监控 &amp; early stopping 四种监视器 Monitor|Description ——-| ———– CaptureVariable | Saves a specified variable’s values into a collection at every n steps of training PrintTensor | Logs a specified tensor’s values at every n steps of training SummarySaver | Saves tf.Summary protocol buffers for a given tensor using a tf.summary.FileWriter at every n steps of training ValidationMonitor | Logs a specified set of evaluation metrics at every n steps of training, and, if desired, implements early stopping under certain conditions 下面这段代码每隔50步评估测试集(注意：如果要看到这些信息，要设置log等级为INFO) validation_monitor = tf.contrib.learn.monitors.ValidationMonitor( test_set.data, test_set.target, every_n_steps=50) ValidationMonitor依赖于checkpoints,所以在初始化classifier时要添加RunConfig，如下所示，表示每隔1秒保存依次checkpoint classifier = tf.contrib.learn.DNNClassifier( feature_columns=feature_columns, hidden_units=[10, 20, 10], n_classes=3, model_dir=&quot;/tmp/iris_model&quot;, config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1)) 自定义 validation_metrics = { &quot;accuracy&quot;: tf.contrib.learn.MetricSpec( metric_fn=tf.contrib.metrics.streaming_accuracy, prediction_key=tf.contrib.learn.PredictionKey.CLASSES), &quot;precision&quot;: tf.contrib.learn.MetricSpec( metric_fn=tf.contrib.metrics.streaming_precision, prediction_key=tf.contrib.learn.PredictionKey.CLASSES), &quot;recall&quot;: tf.contrib.learn.MetricSpec( metric_fn=tf.contrib.metrics.streaming_recall, prediction_key=tf.contrib.learn.PredictionKey.CLASSES)} # 最后三行设置early_stopping，分别代表评估指标，最小化还是最大化，early_stopping的步数 validation_monitor = tf.contrib.learn.monitors.ValidationMonitor( test_set.data, test_set.target, every_n_steps=50, metrics=validation_metrics, early_stopping_metric=&quot;loss&quot;, early_stopping_metric_minimize=True, early_stopping_rounds=200) 可视化 tensorboard --logdir=./tmp/iris_model/ --host=127.0.0.1 --port=6006 8. 可视化tensordef variable_summaries(var): &quot;&quot;&quot;Attach a lot of summaries to a Tensor (for TensorBoard visualization).&quot;&quot;&quot; with tf.name_scope(&apos;summaries&apos;): mean = tf.reduce_mean(var) tf.summary.scalar(&apos;mean&apos;, mean) with tf.name_scope(&apos;stddev&apos;): stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean))) tf.summary.scalar(&apos;stddev&apos;, stddev) tf.summary.scalar(&apos;max&apos;, tf.reduce_max(var)) tf.summary.scalar(&apos;min&apos;, tf.reduce_min(var)) tf.summary.histogram(&apos;histogram&apos;, var) # 调用 with tf.name_scope(&apos;weights&apos;): weights = weight_variable([input_dim, output_dim]) variable_summaries(weights) ... # Merge all the summaries and write them out to /tmp/mnist_logs (by default) merged = tf.summary.merge_all() train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + &apos;/train&apos;, sess.graph) ... summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True)) train_writer.add_summary(summary, step) 可视化命令参照第7条。 9. 打印所有可训练变量with tf.Session() as sess: variables_names =[v.name for v in tf.trainable_variables()] values = sess.run(variables_names) for k,v in zip(variables_names, values): print(k, v) 10. 将稀疏矩阵转换为稠密矩阵tf.sparse_tensor_to_dense(labels, default_value=-1) 注：稀疏矩阵，比如indice=[[0,1],[1,2]],values=[10,32],意思就是，2*3矩阵[[0,10,0],[0,0,32]]，默认将稀疏部分补0. 11. tensorflow实现双向双层RNN双层双向RNNfw_cell = bn_rnn.BNGRUCell(self.config.n_hidden, self.training_placeholder) bw_cell = bn_rnn.BNGRUCell(self.config.n_hidden, self.training_placeholder) fw_cell = tf.nn.rnn_cell.DropoutWrapper(cell=fw_cell, output_keep_prob=self.drop_out_placeholder) bw_cell = tf.nn.rnn_cell.DropoutWrapper(cell=bw_cell, output_keep_prob=self.drop_out_placeholder) fw_cells = tf.nn.rnn_cell.MultiRNNCell([fw_cell] * 2) bw_cells = tf.nn.rnn_cell.MultiRNNCell([bw_cell] * 2 ) _, state = tf.nn.bidirectional_dynamic_rnn(fw_cells,bw_cells,inputs,sequence_length=self.seq_length_placeholder,dtype=tf.float32) outputs = tf.concat((state[0][0], state[0][1], state[1][0], state[1][1]), 1) outputs = tf.reshape(outputs, [self.config.batch_size, 4 * self.config.n_hidden])","categories":[],"tags":[]},{"title":"Shell 常用命令","slug":"shell","date":"2017-09-06T04:38:00.851Z","updated":"2017-09-06T04:12:08.000Z","comments":true,"path":"2017/09/06/shell/","link":"","permalink":"http://zhugy.com/2017/09/06/shell/","excerpt":"","text":"1. 查找字符串并显示行号grep -n &apos;查找我&apos; 文件名","categories":[],"tags":[]},{"title":"pytorch常用命令","slug":"pytorch","date":"2017-09-06T04:38:00.815Z","updated":"2017-09-06T04:12:08.000Z","comments":true,"path":"2017/09/06/pytorch/","link":"","permalink":"http://zhugy.com/2017/09/06/pytorch/","excerpt":"","text":"1. 形状改变x=torch.randn(2,3) x.view(-1, 6)","categories":[],"tags":[]},{"title":"python常用命令","slug":"python","date":"2017-09-06T04:38:00.797Z","updated":"2017-09-06T04:13:22.000Z","comments":true,"path":"2017/09/06/python/","link":"","permalink":"http://zhugy.com/2017/09/06/python/","excerpt":"","text":"1. 使用argparse传递命令行参数 格式 import argparse parser = argparse.ArgumentParser() parser.add_argument( &apos;-v&apos;, &apos;--version&apos;, type=float, default=0.2, help=&apos;the version&apos;) # 对于bool parser.add_argument(&apos;--feature&apos;, dest=&apos;feature&apos;, action=&apos;store_true&apos;) parser.add_argument(&apos;--no-feature&apos;, dest=&apos;feature&apos;, action=&apos;store_false&apos;) args = parser.parse_args() print(args.version) print(args.feature) 调用 python test.py -v 0.3 --feature 2. 获取当前路径os.path.abspath(&apos;.&apos;) #或者 os.system(&apos;pwd&apos;) 3. 判断类型t=[1,2] print(isinstance(t, list)) 4. 对字典排序#按照values从大到小排序 for key, values in sorted(d.items(), key=lambda item:item[1]，reverse=True) print(&apos;key:{}/value:{}&apos;.format(key, value)) 5. 遍历文件的两种方法os.listdir(path) for root, dirs, files in os.walk(path): for file in files: print(file) 6. 删除文件和目录import os import shutil os.remove(&apos;D:/1.txt&apos;) shutil.rmtree(&apos;D:/test/&apos;)","categories":[],"tags":[]},{"title":"maven常用命令","slug":"maven","date":"2017-09-06T04:38:00.780Z","updated":"2017-09-06T04:12:08.000Z","comments":true,"path":"2017/09/06/maven/","link":"","permalink":"http://zhugy.com/2017/09/06/maven/","excerpt":"","text":"1. 打包命令,忽略测试mvn package -Dmaven.test.skip=true -Dmaven.javadoc.skip=true 2. 编译mvn compile 3. 拷贝到本地库mvn install","categories":[],"tags":[]},{"title":"git常用命令","slug":"git","date":"2017-09-06T04:38:00.760Z","updated":"2017-09-06T04:11:17.000Z","comments":true,"path":"2017/09/06/git/","link":"","permalink":"http://zhugy.com/2017/09/06/git/","excerpt":"","text":"1. git stash：清除更改","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2017-09-06T02:52:24.342Z","updated":"2017-09-06T02:52:24.342Z","comments":true,"path":"2017/09/06/hello-world/","link":"","permalink":"http://zhugy.com/2017/09/06/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}